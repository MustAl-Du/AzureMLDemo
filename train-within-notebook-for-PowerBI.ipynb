{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "\n",
        "Licensed under the MIT License."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/training/train-within-notebook/train-within-notebook.png)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and deploy a model\n",
        "_**Create and deploy a model directly from a notebook**_\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "## Contents\n",
        "1. [Introduction](#Introduction)\n",
        "1. [Setup](#Setup)\n",
        "1. [Data](#Data)\n",
        "1. [Train](#Train)\n",
        "    1. Viewing run results\n",
        "    1. Simple parameter sweep\n",
        "    1. Viewing experiment results\n",
        "    1. Select the best model\n",
        "1. [Deploy](#Deploy)\n",
        "    1. Register the model\n",
        "    1. Create a scoring file\n",
        "    1. Create the environment yml file\n",
        "    1. Create the Docker Image\n",
        "    1. Deploy the Docker image as web service on Azure Container Instance\n",
        "    1. Test the Web Service\n",
        "    1. Clean up\n",
        "1. [Next Steps](#nextsteps)\n",
        "\n",
        "---\n",
        "\n",
        "## Introduction\n",
        "Azure Machine Learning provides capabilities to control all aspects of model training and deployment directly from a notebook using the AML Python SDK.  In this notebook we will\n",
        "* connect to our AML Workspace\n",
        "* create an experiment that contains multiple runs with tracked metrics\n",
        "* choose the best model created across all runs\n",
        "* deploy that model as a service\n",
        "\n",
        "In the end we will have a model deployed as a web service which we can call from an HTTP endpoint"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Setup\n",
        "Ensure you have created an Azure Machine Learning (AML) workspace with a running compute instance.Then, open this notebook from within the AML Studio and attach it to the compute instance.\n",
        "\n",
        "For this notebook we need the Azure ML SDK and access to our workspace.  The following cell imports the SDK, checks the version, and accesses our already configured AzureML workspace."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all required libraries\n",
        "# If some of these libraries fail, run pip list and pip install to make sure all required libraries are installed on this environment\n",
        "\n",
        "import azureml.core\n",
        "import joblib\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from azureml.core import Experiment, Workspace, Dataset\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "from azureml.core.environment import Environment\n",
        "from azureml.core.model import Model, InferenceConfig\n",
        "from azureml.core.webservice import AciWebservice, Webservice\n",
        "from azureml.fsspec import AzureMachineLearningFileSystem\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"This notebook was created using version 1.0.2 of the Azure ML SDK\")\n",
        "print(\"You are currently using version\", azureml.core.VERSION, \"of the Azure ML SDK\")\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep='\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": [
          "install"
        ],
        "gather": {
          "logged": 1677877712787
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Data\n",
        "We will use the diabetes dataset for this experiment, a well-known small dataset that comes with scikit-learn. The dataset consists of ten baseline variables: age, sex, body mass index, average blood pressure, and six blood serum measurements that were obtained for each of n = 442 diabetes patients, as well as a quantitative measure of disease progression one year after baseline, as described in [scikit-learn.org](https://scikit-learn.org/stable/datasets/index.html#diabetes-dataset) website. This cell demonstrates how to load this dataset directly from sciket-learn library (load_diabetes) \n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "X, y = load_diabetes(return_X_y = True)\n",
        "\n",
        "print (\"Data contains\", len(X), '442 diabetes patients')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677878005321
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the purpose of this demo, We have created a CSV file from the scikit-learn diabetes dataset that we will use instead. We need to create an AML [Datastore](https://learn.microsoft.com/en-us/azure/machine-learning/concept-data#datastore) (or use the default one), and then create an AML [Dataset](https://learn.microsoft.com/en-us/azure/machine-learning/concept-data#data-asset) and upload the CSV file into it. You can create the AML Datastore and Dataset intuitively in the AML Studio or through the Azure CLI/Python SDK. You can find more details [here](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-datastore?tabs=cli-identity-based-access%2Ccli-adls-identity-based-access%2Ccli-azfiles-account-key%2Ccli-adlsgen1-identity-based-access). You can find the CSV file in the [GitHub Repo](https://github.com/MustAl-Du/AzureMLDemo/blob/main/diabetesDataSet.csv)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variables for the AML Datastore\r\n",
        "datastore_name = 'workspaceblobstore'\r\n",
        "datasource_relativepath = 'UI/2023-03-03_214901_UTC/diabetesDataSet.csv'\r\n",
        "\r\n",
        "uri = 'azureml://subscriptions/'+ws.subscription_id+'/resourcegroups/'+ws.resource_group+'/workspaces/'+ws.name+'/datastores/'+datastore_name+'/paths/'+datasource_relativepath\r\n",
        "\r\n",
        "print(uri)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677880178550
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate file system using datastore URI\r\n",
        "fs = AzureMachineLearningFileSystem(uri)\r\n",
        "\r\n",
        "# use an open context\r\n",
        "with fs.open('/'+datastore_name+'/'+datasource_relativepath) as f:\r\n",
        "        dataset = pd.read_csv(f)\r\n",
        "\r\n",
        "print(\"Loading Diabetes Data from the CSV file...\")\r\n",
        "X, y = dataset[['age', 'gender', 'bmi', 'bp', 'tc', 'ldl', 'hdl', 'tch', 'ltg', 'glu']].values, dataset['y'].values\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\r\n",
        "data = {\r\n",
        "    \"train\":{\"X\": X_train, \"y\": y_train},        \r\n",
        "    \"test\":{\"X\": X_test, \"y\": y_test}\r\n",
        "}\r\n",
        "\r\n",
        "print (\"Data contains\", len(data['train']['X']), \"training samples and\",len(data['test']['y']), \"test samples\")\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677880183571
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Train\n",
        "\n",
        "Let's use scikit-learn to train a simple Ridge regression model.  We use AML to record interesting information about the model in an Experiment.  An Experiment contains a series of trials called Runs.  During this trial we use AML in the following way:\n",
        "* We access an experiment from our AML workspace by name, which will be created if it doesn't exist\n",
        "* We use `start_logging` to create a new run in this experiment\n",
        "* We use `run.log()` to record a parameter, alpha, and an accuracy measure - the Mean Squared Error (MSE) to the run.  We will be able to review and compare these measures in the Azure Portal at a later time.\n",
        "* We store the resulting model in the **working** directory, which is automatically captured by AML when the run is complete.\n",
        "* We use `run.complete()` to indicate that the run is over and results can be captured and finalized"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Get an experiment object from Azure Machine Learning\n",
        "experiment = Experiment(workspace=ws, name=\"train-within-notebook-for-powerbi\")\n",
        "\n",
        "# Create a run object in the experiment\n",
        "run =  experiment.start_logging()\n",
        "# Log the algorithm parameter alpha to the run; where alpha is between 0 and 1\n",
        "run.log('alpha', 0.03)\n",
        "\n",
        "# Create, fit, and test the scikit-learn Ridge regression model\n",
        "regression_model = Ridge(alpha=0.03)\n",
        "regression_model.fit(data['train']['X'], data['train']['y'])\n",
        "preds = regression_model.predict(data['test']['X'])\n",
        "\n",
        "# Output the Mean Squared Error to the notebook and to the run\n",
        "print('Mean Squared Error is', mean_squared_error(data['test']['y'], preds))\n",
        "run.log('mse', mean_squared_error(data['test']['y'], preds))\n",
        "\n",
        "# Save the model to the working directory \n",
        "model_file_name = 'diabetesmodel.pkl'\n",
        "\n",
        "joblib.dump(value = regression_model, filename = model_file_name)\n",
        "\n",
        "# upload the model file explicitly into artifacts \n",
        "run.upload_file(name = model_file_name, path_or_stream = model_file_name)\n",
        "\n",
        "# Complete the run\n",
        "run.complete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": [
          "local run",
          "outputs upload"
        ],
        "gather": {
          "logged": 1677880213029
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Viewing run results\n",
        "Azure Machine Learning stores all the details about the run in the Azure cloud.  Let's access those details by retrieving a link to the run using the default run output.  Clicking on the resulting link will take you to an interactive page presenting all run information."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "run"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677880217849
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple parameter sweep\n",
        "Now let's take the same concept from above and modify the **alpha** parameter.  For each value of alpha we will create a run that will store metrics and the resulting model.  In the end we can use the captured run history to determine which model was the best for us to deploy. \n",
        "\n",
        "Note that by using `with experiment.start_logging() as run` AML will automatically call `run.complete()` at the end of each loop.\n",
        "\n",
        "This example also uses the **tqdm** library to provide a thermometer feedback"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# list of numbers from 0 to 1.0 with a 0.10 interval\n",
        "alphas = np.arange(0.0, 1.0, 0.10)\n",
        "\n",
        "# try a bunch of alpha values in a Linear Regression (Ridge) model\n",
        "for alpha in tqdm(alphas):\n",
        "    # create a bunch of runs, each train a model with a different alpha value\n",
        "    with experiment.start_logging() as run:\n",
        "        # Use Ridge algorithm to build a regression model\n",
        "        regression_model = Ridge(alpha=alpha)\n",
        "        regression_model.fit(X=data[\"train\"][\"X\"], y=data[\"train\"][\"y\"])\n",
        "        preds = regression_model.predict(X=data[\"test\"][\"X\"])\n",
        "        mse = mean_squared_error(y_true=data[\"test\"][\"y\"], y_pred=preds)\n",
        "\n",
        "        # log alpha, mean_squared_error and feature names in run history\n",
        "        run.log(name=\"alpha\", value=alpha)\n",
        "        run.log(name=\"mse\", value=mse)\n",
        "\n",
        "        # Save the model to the outputs directory for capture\n",
        "        joblib.dump(value=regression_model, filename='diabetesmodel.pkl')\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677880280994
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Viewing experiment results\n",
        "Similar to viewing the run, we can also view the entire experiment.  The experiment report view in the Azure portal lets us view all the runs in a table, and also allows us to customize charts.  This way, we can see how the alpha parameter impacts the quality of the model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# now let's take a look at the experiment in Azure portal.\n",
        "experiment"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677880312415
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select the best model \n",
        "Now that we've created many runs with different parameters, we need to determine which model is the best for deployment.  For this, we will iterate over the set of runs.  From each run we will take the *run id* using the `id` property, and examine the metrics by calling `run.get_metrics()`.  \n",
        "\n",
        "Since each run may be different, we do need to check if the run has the metric that we are looking for, in this case, **mse**.  To find the best run, we create a dictionary mapping the run id's to the metrics.\n",
        "\n",
        "Finally, we use the `tag` method to mark the best run to make it easier to find later. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "runs = {}\n",
        "run_metrics = {}\n",
        "\n",
        "# Create dictionaries containing the runs and the metrics for all runs containing the 'mse' metric\n",
        "for r in tqdm(experiment.get_runs()):\n",
        "    metrics = r.get_metrics()\n",
        "    if 'mse' in metrics.keys():\n",
        "        runs[r.id] = r\n",
        "        run_metrics[r.id] = metrics\n",
        "\n",
        "# Find the run with the best (lowest) mean squared error and display the id and metrics\n",
        "best_run_id = min(run_metrics, key = lambda k: run_metrics[k]['mse'])\n",
        "best_run = runs[best_run_id]\n",
        "print('Best run is:', best_run_id)\n",
        "print('Metrics:', run_metrics[best_run_id])\n",
        "\n",
        "# Tag the best run for identification later\n",
        "best_run.tag(\"Best Run\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677880334749
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Deploy\n",
        "Now that we have trained a set of models and identified the run containing the best model, we want to deploy the model for real time inference.  The process of deploying a model involves\n",
        "* registering a model in your workspace\n",
        "* creating a scoring file containing init and run methods\n",
        "* creating an environment dependency file describing packages necessary for your scoring file\n",
        "* deploying the model and packages as a web service"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register a model\n",
        "We have already identified which run contains the \"best model\" by our evaluation criteria.  Each run has a file structure associated with it that contains various files collected during the run.  Since a run can have many outputs we need to tell AML which file from those outputs represents the model that we want to use for our deployment.  We can use the `run.get_file_names()` method to list the files associated with the run, and then use the `run.register_model()` method to place the model in the workspace's model registry.\n",
        "\n",
        "When using `run.register_model()` we supply a `model_name` that is meaningful for our scenario and the `model_path` of the model relative to the run.  In this case, the model path is what is returned from `run.get_file_names()`"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# View the files in the run\n",
        "for f in best_run.get_file_names():\n",
        "    print(f)\n",
        "    \n",
        "# Register the model with the workspace\n",
        "model = Model.register(model_path = \"diabetesmodel.pkl\",\n",
        "                       model_name = \"diabetesmodel.pkl\",\n",
        "                       tags = {'area': \"diabetes\", 'type': \"regression\"},\n",
        "                       description = \"Ridge regression model to predict diabetes\",\n",
        "                       workspace =ws)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": [
          "query history"
        ],
        "gather": {
          "logged": 1677880345919
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once a model is registered, it is accessible from the list of models on the AML workspace.  If you register models with the same name multiple times, AML keeps a version history of those models for you.  The `Model.list()` lists all models in a workspace, and can be filtered by name, tags, or model properties.   "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Find all models called \"best_model\" and display their version numbers\n",
        "models = Model.list(ws, name='diabetesmodel.pkl')\n",
        "for m in models:\n",
        "    print(m.name, m.version)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": [
          "register model from history"
        ],
        "gather": {
          "logged": 1677880369265
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a scoring file"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since your model file can essentially be anything you want it to be, you need to supply a scoring script that can load your model and then apply the model to new data. This script is your 'scoring file'. This scoring file is a python program containing, at a minimum, two methods init() and run(). The init() method is called once when your deployment is started so you can load your model and any other required objects. This method uses the get_model_path function to locate the registered model inside the docker container. The run() method is called interactively when the web service is called with one or more data samples to predict.\n",
        "\n",
        "Important: The schema decorators for pandas and numpy are required to implement the automatic swagger schema generation for input and output variables\n",
        "\n",
        "After a successful run of the this script, the score.py file be created in the working folder\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile score.py\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from azureml.core.model import Model\n",
        "\n",
        "\n",
        "\n",
        "from inference_schema.schema_decorators import input_schema, output_schema\n",
        "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n",
        "from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\n",
        "\n",
        "def init():\n",
        "    global model\n",
        "    model_path = Model.get_model_path('diabetesmodel.pkl')\n",
        "    # deserialize the model file back into a sklearn model\n",
        "    model = joblib.load(model_path)\n",
        "\n",
        "input_sample = pd.DataFrame(data=[{\n",
        "            \"input1_age\": 59,\n",
        "            \"input2_gender\": 2,\n",
        "            \"input3_bmi\": 32,\n",
        "            \"input4_bp\": 101,\n",
        "            \"input5_tc\": 157,\n",
        "            \"input6_ldl\": 93,\n",
        "            \"input7_hdl\": 38,\n",
        "            \"input8_tch\": 4,\n",
        "            \"input9_ltg\": 5,\n",
        "            \"input10_glu\": 87\n",
        "            }])\n",
        "output_sample = np.array([0])\n",
        "\n",
        "@input_schema('data', PandasParameterType(input_sample))\n",
        "@output_schema(NumpyParameterType(output_sample))\n",
        "\n",
        "def run(data):\n",
        "    try:\n",
        "        print(\"input_data....\")\n",
        "        print(data.columns)\n",
        "        print(type(data))\n",
        "        result = model.predict(data)\n",
        "        print(\"result.....\")\n",
        "        print(result)\n",
        "        return result.tolist()\n",
        "    except Exception as e:\n",
        "        error = str(e)\n",
        "        return error"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the environment yml file\n",
        "\n",
        "This step will create the yml file (myenv.yml) in the working folder for this deployment\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "env = Environment('deploytocloudenv')\n",
        "env.python.conda_dependencies = CondaDependencies.create(conda_packages=['numpy','pandas', 'scikit-learn'],pip_packages=['azureml-defaults','inference-schema[numpy-support]'])\n",
        "inference_config = InferenceConfig(entry_script=\"score.py\", environment=env)\n",
        "\n",
        "with open (\"myenv.yml\",\"w\") as f:\n",
        "   f.write(env.python.conda_dependencies.serialize_to_string())\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677880648542
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deploy the Docker image as a web service on Azure Container Instance\n",
        "\n",
        "Note that the service creation can take few minutes."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
        "                                               memory_gb = 1, \n",
        "                                               tags = {'area': \"diabetes\", 'type': \"regression\"}, \n",
        "                                               description = 'aci web service with the diabetes regression model',\n",
        "                                               location = 'East US')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": [
          "deploy service",
          "aci",
          "sample-aciwebservice-deploy-config"
        ],
        "gather": {
          "logged": 1677880715215
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the webservice using all of the precreated configurations and our best model\n",
        "aciWebservice = Model.deploy(workspace=ws,\n",
        "                       name='aci-webservice-diabetesmodel',\n",
        "                       models=[model],\n",
        "                       inference_config=inference_config,\n",
        "                       deployment_config=aciconfig,\n",
        "                       overwrite=True)\n",
        "\n",
        "# Wait for the service deployment to complete while displaying log output\n",
        "aciWebservice.wait_for_deployment(show_output=True)\n",
        "print(aciWebservice.state)\n",
        "print(aciWebservice.get_logs)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": [
          "deploy service",
          "aci",
          "sample-aciwebservice-deploy-from-image"
        ],
        "gather": {
          "logged": 1677881523475
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the swagger URI for the deployed ACI WebService\r\n",
        "aciWebservice.swagger_uri"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": [
          "Test the auto-generated Swagger interface/n"
        ],
        "gather": {
          "logged": 1677881648214
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test web service"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call the web service with some dummy input data to get a prediction."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "test_sample = json.dumps({\"data\": [{\n",
        "        \"input1_age\": 59,\n",
        "        \"input2_sex\": 2,\n",
        "        \"input3_bmi\": 32,\n",
        "        \"input4_bp\": 101,\n",
        "        \"input5_s1\": 157,\n",
        "        \"input6_s2\": 93,\n",
        "        \"input7_s3\": 38,\n",
        "        \"input8_s4\": 4,\n",
        "        \"input9_s5\": 5,\n",
        "        \"input10_s10\": 87,}]})\n",
        "\n",
        "test_sample = bytes(test_sample,encoding = 'utf8')\n",
        "\n",
        "prediction = aciWebservice.run(input_data=test_sample)\n",
        "print(prediction)\n",
        "print(round(prediction[0]))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677881693210
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clean up"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delete the ACI instance to stop the compute and any associated billing."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "aciWebservice.delete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": [
          "deploy service",
          "aci"
        ]
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='nextsteps'></a>\n",
        "## Next Steps"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, you created a models inside the notebook using local data, stored them inside an AML experiment, found the best one and deployed it as a live service!  From here you can continue to use Azure Machine Learning in this regard to run your own experiments and deploy your own models, or you can expand into further capabilities of AML!\n",
        "\n",
        "Now, you are ready to use Power BI Desktop to infer this model leveraging the native integration between Power BI and AML. Refer to the instruction in [Power BI Integration with Azure ML Model](https://github.com/MustAl-Du/AzureMLDemo/blob/main/Power%20BI%20Integration%20with%20Azure%20ML%20Model.docx)."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "index_order": 1,
    "exclude_from_index": false,
    "task": "Training and deploying a model from a notebook",
    "deployment": [
      "Azure Container Instance"
    ],
    "authors": [
      {
        "name": "roastala"
      }
    ],
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "compute": [
      "Local"
    ],
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "tags": [
      "None"
    ],
    "datasets": [
      "Diabetes"
    ],
    "category": "tutorial",
    "framework": [
      "None"
    ],
    "friendly_name": "Train and deploy a model using Python SDK",
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}